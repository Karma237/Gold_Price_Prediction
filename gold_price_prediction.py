# -*- coding: utf-8 -*-
"""Gold-Price-Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TEGY2P6xmAyoNt2ZH38PmCrq1fsjOZM3

Name: Karma Yasser Ismail 

Project: Gold Price Predicition

 ***Data Science Intern associated by CodeClause***
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
pd.plotting.register_matplotlib_converters()
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.ensemble import RandomForestRegressor
import numpy as np

# To Select file from your device 
from google.colab import files
uploaded = files.upload()

# Read Data
data = pd.read_csv('GoldPrice.csv', na_values=['null'],index_col="Date", parse_dates=True)
data.head()

data.info() # Brief Information

data.isnull().values.any() # Check Nulls

data.duplicated().values.any() # Check Duplication

data.describe() # Analyze Data

# Plot target var Annual Change
plt.figure(figsize=(10,6))
plt.title("Annual change of Gold from 2008-2018")
sns.lineplot(data=data['GLD'], label="Gold")
plt.xlabel("Date")

# Linear Relation aka Correlation
correlation = data.corr()
plt.figure(figsize = (10,6))
sns.heatmap(correlation,  annot=True)
plt.title('Correlation of data Features')
plt.show()

# Close up on linear relation with target var
print (correlation['GLD'].sort_values(ascending=False), '\n')

# Check data distribution of our target variable against the density distribution
sns.distplot(data['GLD'], color='green')

print('Skewness: %f', data['GLD'].skew()) # measures the symmetry of the distribution / outlier direction
print("Kurtosis: %f" % data['GLD'].kurt()) # where the most information is lying  /analyze the outliers in a given data.

# Plot Gold against each feature density
sns.pairplot(data, hue ='GLD')

# SLV against gld density
sns.kdeplot(data=data,x='SLV', y='GLD',shade=True)
plt.title("Distribution of SLV, by GLD")
plt.show()

x = data.drop(['GLD'],axis=1)
y = data['GLD']

x

y

# Spliting the dataset into training and test set
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)

# data Standardization
sc = StandardScaler()
x_train = pd.DataFrame(sc.fit_transform(x_train), columns=x_train.columns)
x_test = pd.DataFrame(sc.transform(x_test), columns=x_test.columns)

x_train

# Modeling
RFR = RandomForestRegressor(n_estimators = 100, random_state = 0)
RFR.fit(x_train, y_train)
y_pred = RFR.predict(x_test)

# Now Check the error for regression

print('Mean Absolute Error :'," ", metrics.mean_absolute_error(y_test,y_pred))
print('Mean Square Error :'," ", metrics.mean_squared_error(y_test,y_pred))
print('Root Mean Square Error :'," ", np.sqrt(metrics.mean_squared_error(y_test,y_pred)))
print("R Squared Error : ", metrics.r2_score(y_test, y_pred ))

# Check the Training and Test set Accuracy
accuracy_train = RFR.score(x_train, y_train)
accuracy_test = RFR.score(x_test, y_test)
print("TRAIN :-" ,accuracy_train * 100, "%")
print("TEST :-" ,accuracy_test * 100 , "%")

y_test = list(y_test)

# Visualising the Accuracy of Predicted result
plt.figure(figsize=(12,8))
plt.plot(y_test, color = 'darkblue', label = 'Acutal')
plt.plot(y_pred, color = 'Red', label = 'Predicted')
plt.title('Acutal Price vs Predicted Price')
plt.xlabel('Number of Oberservation')
plt.ylabel('Gold Price')
plt.legend()
plt.show()